{
  "lc": 1,
  "type": "constructor",
  "id": [
    "langsmith",
    "playground",
    "PromptPlayground"
  ],
  "kwargs": {
    "first": {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain_core",
        "prompts",
        "structured",
        "StructuredPrompt"
      ],
      "kwargs": {
        "input_variables": [
          "input",
          "output"
        ],
        "messages": [
          {
            "lc": 1,
            "type": "constructor",
            "id": [
              "langchain",
              "prompts",
              "chat",
              "SystemMessagePromptTemplate"
            ],
            "kwargs": {
              "prompt": {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "prompt",
                  "PromptTemplate"
                ],
                "kwargs": {
                  "input_variables": [],
                  "template_format": "mustache",
                  "template": "You are an expert data labeler in charge of reviewing AI outputs. The AI outputs may involve the AI searching the web or other data sources to ground its answer. Your job is to assess how complete the answer to a given question is\n\n<Rubric>\nA complete answer:\n- Provides a full answer to all aspects of the question.\nWhen scoring, you should deduct points for:\n- Indication that the sources available to the AI were not sufficient to answer the question.\n- Vague or unhelpful answers that do not address the question.\n- Significant portions of the question(s) left unaddressed in the answer\n</Rubric>"
                }
              }
            }
          },
          {
            "lc": 1,
            "type": "constructor",
            "id": [
              "langchain",
              "prompts",
              "chat",
              "HumanMessagePromptTemplate"
            ],
            "kwargs": {
              "prompt": {
                "lc": 1,
                "type": "constructor",
                "id": [
                  "langchain",
                  "prompts",
                  "prompt",
                  "PromptTemplate"
                ],
                "kwargs": {
                  "input_variables": [
                    "input",
                    "output"
                  ],
                  "template_format": "mustache",
                  "template": "Please grade the following example according to the above instructions:\n\n<example>\n<question>\n{{input}}\n</question>\n\n<output>\n{{output}}\n</output>\n</example>"
                }
              }
            }
          }
        ],
        "schema_": {
          "title": "extract",
          "description": "Extract information from the user's response.",
          "type": "object",
          "properties": {
            "completeness": {
              "type": "number",
              "description": "Is the output a complete answer to the question? Min (0): Incomplete answer that does not address the question or has insufficient sources| Max (1): Complete answer that fully addresses the question",
              "minimum": 0,
              "maximum": 1
            },
            "comment": {
              "type": "string",
              "description": "Reasoning for the score"
            }
          },
          "required": [
            "completeness"
          ]
        }
      },
      "name": "StructuredPrompt"
    },
    "last": {
      "lc": 1,
      "type": "constructor",
      "id": [
        "langchain",
        "chat_models",
        "openai",
        "ChatOpenAI"
      ],
      "kwargs": {
        "temperature": 1,
        "top_p": 1,
        "presence_penalty": null,
        "frequency_penalty": null,
        "model": "gpt-5-mini",
        "extra_headers": {},
        "openai_api_key": {
          "id": [
            "OPENAI_API_KEY"
          ],
          "lc": 1,
          "type": "secret"
        }
      }
    }
  }
}