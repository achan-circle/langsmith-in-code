{
  "lc": 1,
  "type": "constructor",
  "id": [
    "langchain_core",
    "prompts",
    "structured",
    "StructuredPrompt"
  ],
  "kwargs": {
    "input_variables": [
      "input",
      "output",
      "reference"
    ],
    "messages": [
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "SystemMessagePromptTemplate"
        ],
        "kwargs": {
          "prompt": {
            "lc": 1,
            "type": "constructor",
            "id": [
              "langchain",
              "prompts",
              "prompt",
              "PromptTemplate"
            ],
            "kwargs": {
              "input_variables": [],
              "template": "You are an expert data labeler given the task of grading AI outputs. The AI will be deciding what the correct next action to take is given a conversation history. The correct action may or may not involve a tool call. You have been given the AIs output, as well as a reference output of what a suitable next action would look like.\n\nPlease grade whether the AI submitted the correct next action. Note: Tool calls do not need to be identical to be considered correct. As long as the arguments supplied make sense in context of the input, and are roughly aligned with the reference output, the output should be treated as correct.\n\nFor example, if the AI needs to schedule an hour long meeting, and there is availability from 9 AM - 12 AM, a meeting scheduled at 9 AM and a meeting scheduled at 10 AM should both be considered correct answers. \n\nREMEMBER: Only evaluate the output's correctness as a next action. If the output does not contain all the steps until the task is complete, that is okay. Only penalize the output if it's missing steps from the reference output.\n",
              "template_format": "f-string"
            },
            "name": "PromptTemplate"
          }
        }
      },
      {
        "lc": 1,
        "type": "constructor",
        "id": [
          "langchain",
          "prompts",
          "chat",
          "HumanMessagePromptTemplate"
        ],
        "kwargs": {
          "prompt": {
            "lc": 1,
            "type": "constructor",
            "id": [
              "langchain",
              "prompts",
              "prompt",
              "PromptTemplate"
            ],
            "kwargs": {
              "input_variables": [
                "input",
                "output",
                "reference"
              ],
              "template": "\nPlease grade the following example according to the above instructions:\n\n<example>\n<input>\n{input}\n</input>\n\n<output>\n{output}\n</output>\n\n<reference_outputs>\n{reference}\n</reference_outputs>\n</example>\n",
              "template_format": "f-string"
            },
            "name": "PromptTemplate"
          }
        }
      }
    ],
    "schema_": {
      "properties": {
        "correctness": {
          "description": "Is the agents action correct based on the reference output?",
          "type": "boolean"
        }
      },
      "required": [
        "correctness"
      ],
      "title": "extract",
      "type": "object",
      "description": "Extract information from the user's response."
    }
  },
  "name": "StructuredPrompt"
}